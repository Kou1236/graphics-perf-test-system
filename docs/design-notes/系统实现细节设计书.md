# 系统实现细节设计书
项目：面向图形应用程序的性能测试系统



[TOC]

## 1. 技术栈
- 后端：Java Spring Boot
- DB：SQLite
- 前端：Web UI（React/Vue）+ 图表库
- 采集实现：Java 后端 + Python Collector（psutil / NVML）
- 扩展模块：OpenGL 注入/Hook

> 注：Windows：DLL 注入或替代的拦截方式；Linux：LD_PRELOAD 等——实现可按平台选一种

- LLM：
  - 调用方式：通过 HTTP API 调用大语言模型（云端或本地部署），由后端封装为 LLMService
  - 使用模式：
    1) ScriptGenerator：生成/修复 GUI 动作脚本（DSL）
    2) BenchmarkGenerator（开发者模式）：生成函数级/渲染级性能测试代码

## 2. 数据模型设计

### 2.1 实体定义
**Application**
- id (PK)
- name
- exePath
- defaultArgs
- workDir
- notes
- createdAt/updatedAt

**Scene**
- id (PK)
- name
- appId (FK)
- durationSec
- warmupSec
- sampleIntervalMs
- metricSetJson（例：["CPU","MEM","GPU","FPS","RENDER_EVENTS"]）
- runtimeConfigJson（分辨率、全屏、vsync 等）
- scriptVersionId（可空）
- renderProbeConfigJson（可空，OpenGL 注入开关与参数）
- createdAt/updatedAt

**ScriptVersion**
- id (PK)
- sceneId (FK)
- version (int)
- dslJson (text)
- checksum
- createdAt/createdBy

**Run**
- id (PK)
- sceneId (FK)
- scriptVersionId（执行时固定）
- status（Pending/Running/Completed/Failed/Aborted）
- startAt/endAt
- pid
- exitCode
- errorMessage
- contextJson（OS/硬件/驱动/显示/电源）
- artifactPathsJson（日志、CSV、RenderTrace 等）
- createdAt

**MetricSample**
- id (PK)
- runId (FK)
- ts (epoch ms)
- cpuPct
- memBytes
- gpuPct (optional)
- fps (optional)
- frameTimeMs (optional)
- extraJson

**RenderEvent（Extension，可选表或文件化存储）**
- id (PK)
- runId (FK)
- ts (epoch ms)
- eventType（DRAW_CALL/SWAP/STATE_CHANGE 等）
- apiName（glDrawArrays/glDrawElements/SwapBuffers 等）
- paramsJson（count, mode 等）
- threadId（optional）
- frameIndex（optional）

**RunSummary**
- runId (PK)
- avgCpu/maxCpu
- avgMem/maxMem
- avgGpu/maxGpu (optional)
- avgFps/minFps/p95FrameTime (optional)
- drawCallsPerFrameAvg (optional)
- swapsPerSecAvg (optional)
- sampleCount
- stableWindowStart/end

**GeneratedTestArtifact（LLM 生成产物，扩展）**
- id (PK)
- type（SCRIPT / BENCHMARK_CODE）
- inputContextJson（函数签名/上下文/提示信息）
- generatedContent（脚本或源码文本）
- status（DRAFT / REVIEWED / DISCARDED）
- linkedScriptVersionId（可空）
- createdAt/createdBy

## 3. API 设计（REST）

### 3.1 Application/Scene
- POST /apps
- GET /apps
- GET /apps/{id}
- POST /scenes
- GET /scenes
- GET /scenes/{id}

### 3.2 Script 版本管理
- POST /scenes/{id}/scripts:generate （可选，LLM）
- POST /scenes/{id}/scripts （固化脚本版本）
- GET /scenes/{id}/scripts
- GET /scripts/{id}
- POST /llm/benchmark:generate
  body:
    - functionSignature
    - headerFiles
    - contextObjects
    - dataStructures
    - testScenarioHints
  返回：
    - benchmarkSourceCode（需人工审核）

### 3.3 Run
- POST /runs body: { sceneId, overrides? } -> runId
- GET /runs/{id}
- POST /runs/{id}:abort
- GET /runs/{id}/samples?from=&to=&limit=
- GET /runs/{id}/summary

### 3.4 对比
- GET /compare?runIds=...
- （可选）GET /compare/samples?runIds=...

### 3.5 OpenGL 注入扩展
- POST /scenes/{id}/render-probe （配置 renderProbeConfigJson）
- GET /runs/{id}/render-events （若存表）
- GET /runs/{id}/render-summary （渲染级统计）

## 4. Run 执行与状态机

### 4.1 状态机
- Pending：已创建
- Running：已启动并采集
- Completed：正常结束
- Failed：启动失败/崩溃/采集失败
- Aborted：用户终止

### 4.2 执行流程
1) 创建 Run（Pending）
2) Runner 启动 AUT：
- command = exePath + args（Scene.runtimeConfig + overrides）
- workDir = Application.workDir
- 记录 pid/startAt，更新 Run -> Running
3) 若启用 OpenGL Probe（Extension）：
- 在启动前/后挂载注入模块（按平台实现）
- 设置 RenderEvent 输出路径（artifact）
4) 启动 Metrics Collector：
- intervalMs 周期采样
- 异步批量写 MetricSample
5) 若 Scene 绑定 ScriptVersion：
- Script Executor 读取 DSL 并执行（含 wait/assert 同步点）
6) 结束：
- 达到 durationSec 或进程提前退出
- 优雅关闭失败后 kill（超时策略）
7) 停止采集与工具
8) 更新 Run：endAt/exitCode/status
9) Analyzer：
- 生成 RunSummary（扣除 warmupSec）
- 若存在 RenderEvent，生成 render-summary 并合并展示

## 5. 动作脚本 DSL（确定性执行）

### 5.1 设计原则
- 结构化、可校验、可版本控制
- 支持同步点：WAIT_VISIBLE / ASSERT
- 执行可追踪：记录失败步、耗时与截图（可选）

### 5.2 DSL 动作类型
- FOCUS_WINDOW(titleContains)
- KEYS(keys)
- CLICK(selector)
- TYPE_TEXT(text)
- DRAG(from,to,durationMs)
- WAIT(ms)
- WAIT_VISIBLE(selector,timeoutMs)
- WAIT_TEXT(selector,contains,timeoutMs)
- ASSERT_VISIBLE(selector)
- ASSERT_TEXT(selector,contains)

## 6. 指标采集与 Provider 插件化

### 6.1 Collector 调度
- 定时器触发 sample
- 从多个 Provider 拉取 MetricPartial
- 合并为 MetricSample 写库（批量写入）

### 6.2 Providers
- CpuMemProvider（必做）：按 PID 获取 cpuPct/memBytes
- GpuProvider（可选）：整体 gpuPct、显存等（NVML 优先）
- FpsProvider（可选）：
  - 协作：解析 AUT 日志输出 FPS
  - 工具：外部工具 CSV 解析得到 fps/frameTime
- RenderProbeProvider（Extension）：
  - 读取 RenderEvent（文件/IPC/DB）
  - 计算 drawcalls/frame、swaps/sec、提交峰值等统计

## 7. Analyzer（统计与对比）
输入：samples（排除 warmup）
输出：RunSummary
- avg/max CPU、avg/max MEM
- （可选）FPS avg/min、frameTime P95
- （Extension）drawCallsPerFrameAvg、swapsPerSecAvg
对比：同 Scene 多 run 的 summary 对比表；可选曲线叠加。

## 8. OpenGL API 注入扩展模块设计（Extension）

### 8.1 模块定位
- 目标：提供渲染函数级观测与“渲染级输入（Render-level Input）”的实验能力。

### 8.2 最小插桩范围
- Swap 相关：SwapBuffers/wglSwapLayerBuffers（Windows）或 glXSwapBuffers/eglSwapBuffers（Linux）
- Draw 相关：glDrawArrays/glDrawElements（可选扩展至 instanced）
- 仅记录必要参数：mode/count/type 等

### 8.3 输出与数据形态
- 输出 RenderEvent 流（JSONL/CSV/二进制均可；MVP 建议 JSONL）
- 每条事件含：ts、apiName、eventType、frameIndex（可推导）、params

### 8.4 风险控制
- 可开关：Scene.renderProbeConfigJson 控制启用
- 最小化开销：采样式记录或仅关键 API
- 回退机制：注入失败不阻断 Run 主流程（仅标记 render probe unavailable）

## 9. LLM 辅助测试生成模块设计

### 9.1 设计动机

在图形应用程序性能测试过程中，测试输入与测试用例的构造往往具有如下特点：

- GUI 操作路径复杂，状态依赖强，手动编写动作脚本成本较高；
- 渲染与图形引擎中的核心函数（如着色器编译、几何体剔除、渲染管线提交等）
  依赖复杂的图形上下文与多种数据结构，手写函数级性能测试用例繁琐且易出错。

为降低测试用例构造成本、提升测试覆盖率与测试效率，
本系统引入 **LLM（Large Language Model）作为辅助测试生成工具**，
用于在测试准备阶段自动生成测试输入或测试代码草稿。

---

### 9.2 使用模式划分

本系统将 LLM 的使用划分为两种互相独立的模式，以适配不同用户角色与测试需求。

---

#### 9.2.1 测试工程师模式：GUI 动作脚本生成

**目标**  
辅助生成或修复 GUI 动作脚本（DSL），用于驱动图形应用进入稳定、可测试状态。

**输入上下文**
- 测试目标的自然语言描述
- 被测应用的界面操作说明或约定
- 动作脚本 DSL 规范与约束条件

**输出结果**
- 动作脚本草稿（Draft Script）

**处理流程**
1. 用户发起脚本生成请求（`POST /scenes/{id}/scripts:generate`）
2. 后端构造 Prompt 并调用 LLM
3. LLM 返回 DSL 格式的脚本草稿
4. 用户对脚本进行人工审核与修订
5. 审核通过后固化为 `ScriptVersion`
6. 后续 Run 执行仅使用已固化的 ScriptVersion

---

#### 9.2.2 开发者模式：函数级 / 渲染级性能测试代码生成

**目标**  
辅助生成针对图形引擎或渲染模块中核心函数的性能测试代码，
用于函数级或渲染级性能分析实验。

**输入上下文（最小化上下文原则）**
- 待测函数的完整签名
- 所属类及相关头文件
- 依赖的核心图形上下文对象（如 `Renderer`、`GraphicsDevice`）
- 关键数据结构定义（如 `Mesh`、`Material`、`Camera`）
- 测试场景提示（输入规模、重复次数、参数组合等）

**输出结果**
- 包含上下文初始化、测试输入构造与计时代码的性能测试源码
  （如 C/C++ benchmark 程序）

**处理流程**
1. 开发者调用 `POST /llm/benchmark:generate` 接口提交上下文信息
2. 系统构造开发者模式 Prompt 并调用 LLM
3. LLM 返回性能测试代码草稿
4. 开发者进行人工审核与必要修改
5. 将代码编译为独立的 benchmark 可执行程序
6. 将该程序作为普通 `Application` 注册进系统
7. 由系统统一进行 Run 执行、指标采集与分析

**说明**
- 系统不直接执行 LLM 生成的源码
- LLM 生成的 benchmark 程序完全复用现有 Run / Collector / Analyzer 流程

---

### 9.3 LLM 生成产物管理

系统通过 `GeneratedTestArtifact` 实体对 LLM 生成结果进行管理：

- SCRIPT 类型：对应 GUI 动作脚本草稿  
- BENCHMARK_CODE 类型：对应函数级/渲染级测试源码  

每个生成产物均包含：
- 生成所用的上下文信息（`inputContextJson`）
- 当前审核状态（DRAFT / REVIEWED / DISCARDED）
- 与正式测试输入（如 ScriptVersion）的关联关系（可选）

该实体仅用于测试生成阶段，不参与 Run 执行阶段的数据流转。

## 10. 验收标准
MVP 验收：
- App/Scene/Run 全流程闭环
- 采集 CPU/内存 samples，并生成 summary
- UI 展示曲线与对比

扩展验收：
- OpenGL 注入可生成 RenderEvent
- 至少输出一个渲染级统计指标（drawcalls/frame 或 swaps/sec）
- 报告页可展示渲染级统计与系统级指标联合分析