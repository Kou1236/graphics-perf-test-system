# 系统架构设计书
毕设项目：面向图形应用程序的性能测试系统



[TOC]

## 1. 文档目的
定义系统目标、边界、总体架构、关键组件与部署形态，为实现与验收提供一致依据。

系统面向图形应用程序（含 OpenGL 程序），支持系统级性能采样与可复现的测试执行；并提供可选模块：OpenGL API 注入（渲染函数级输入/观测）。

## 2. 系统目标与范围

### 2.1 核心目标
1. 对本地图形应用程序（以 exe 形式运行）进行**系统级性能测试**。

2. 支持“配置→执行→采集→分析→可视化/报告”的流程。

3. 支持 **LLM 辅助测试生成能力**，包括：
      - 面向测试工程师的 GUI 动作脚本生成/修复；
      - 面向开发者的函数级/渲染级性能测试代码生成（以独立 benchmark 程序形式存在）。

4. 引入 **OpenGL API 注入/Hook 模块**：

   - 作为“渲染函数级输入/观测”能力，用于构建更可控的渲染复杂度测试、隔离变量实验与渲染提交行为分析。

   - 该模块为“可选启用”，不作为系统级性能回归测试的必要前提。

## 3. 用户角色与核心用例

### 3.1 角色
- 测试工程师：配置应用与场景、发起 Run、查看报告与对比。
- 开发者：关注版本性能回归与异常波动。

### 3.2 核心用例
- UC-01 注册被测应用（Application）
- UC-02 创建测试场景（Scene）
- UC-03 绑定/选择脚本版本（ScriptVersion）
- UC-04 发起执行（Run）
- UC-05 查看 Run 详情与 Summary（曲线/统计）
- UC-06 对比多个 Run（同场景/不同版本）
- UC-07 LLM 生成/修复脚本并固化版本
- UC-08 启用 OpenGL 注入：采集渲染函数级事件/生成 RenderScript 并执行阶梯测试
- UC-09 LLM 辅助生成函数级/渲染级性能测试程序（Developer Mode）：
  - 输入：目标渲染函数签名、最小图形上下文信息、数据结构说明
  - 输出：可编译的 benchmark 测试代码
  - 由开发者审核并编译为独立 exe，再作为 Application 纳入系统测试

## 4. 总体架构

### 4.1 分层架构
系统采用三层结构：

1. 控制平面（Control Plane）

   - Web UI：配置、执行、报告展示

   - API Service：应用/场景/脚本/Run 管理与查询接口

2. 执行平面（Execution Plane）

   - Runner：启动/停止被测 exe，维护 Run 生命周期

   - Script Executor：确定性动作脚本回放（UI 自动化/输入驱动）

   - Metrics Collector：采集 CPU/内存/（可选 GPU/FPS）并记录

   - OpenGL Injection Agent：可选启用的渲染函数级插桩与事件输出

3. 数据平面（Data Plane）

   - Storage：配置、元数据、时序采样、外部工具产物

   - Analyzer：统计分析与对比（avg/max/p95 等）

   - Report：曲线与表格输出（可选导出）

### 4.2 逻辑组件说明
- **Application/Scene/ScriptVersion Manager**：配置与版本管理
- **Run Orchestrator**： Run 状态机与任务调度
- **Process Controller**： 进程启动/终止、PID/退出码获取
- **Metric Providers**： CPU/MEM/GPU/FPS 插件式采集
- **Script Executor**： DSL 动作执行与同步点（wait/assert）
- **Analyzer**：对 samples 进行统计并生成 RunSummary
- **OpenGL Injection Module**：
  - 提供“渲染函数级事件（Draw/Swap 等）”采集
  - 可输出 RenderTrace/RenderScript，用于阶梯测试与变量隔离实验

### 4.3 核心数据流
1. 用户创建 Application、Scene，绑定 ScriptVersion
2. 发起 Run（POST /runs）
3. Runner 启动被测 exe，记录 PID，进入 Running
4. Script Executor回放动作脚本，驱动场景进入稳定状态
5. Metrics Collector 周期采样并写入 MetricSample
6. Run 到时结束或被测进程退出；写入 endAt/exitCode/status
7. Analyzer 生成 RunSummary
8. UI 展示曲线与对比

### 4.4 OpenGL 注入扩展数据流
1. 在 Scene/Run 中启用 `render_probe=opengl_injection`
2. Runner 启动时加载注入模块（仅对 OpenGL 应用）
3. 注入模块输出 RenderEvent（如 glDraw*/SwapBuffers）到本地文件或 IPC
4. Collector 解析 RenderEvent：
   - 生成 RenderTrace/RenderMetrics（drawcalls/frame、swap interval 等）
   - 可固化为 RenderScript（渲染级输入脚本）用于阶梯测试
5. Analyzer 合并系统级指标与渲染级指标输出扩展报告

### 4.5 LLM 辅助测试生成模块

LLM 在本系统中不直接参与性能测试执行，而作为“测试生成工具”存在，分为两种使用模式：

#### 4.5.1 测试工程师模式
- 输入：测试目标描述、应用 UI 操作说明、DSL 约束
- 输出：动作脚本草稿（Draft Script）
- 经人工审核后固化为 ScriptVersion
- 用于系统级性能测试的确定性输入驱动

#### 4.5.2 开发者模式
- 输入：
  - 目标函数完整签名
  - 所属类与头文件
  - 所需图形上下文对象（如 Renderer、GraphicsDevice）
  - 关键数据结构（如 Mesh、Material、Camera）
- 输出：
  - 包含上下文初始化、参数构造与计时代码的性能测试程序源码
- 生成结果不直接执行，需由开发者审核、编译为独立 benchmark 可执行程序
- 编译后的程序可作为普通 Application 注册并由本系统执行与采集

## 5. 关键架构原则

### 5.1 可复现性优先
- 性能基准执行阶段仅使用固化脚本版本（ScriptVersion）。
- 丢弃 warm-up 阶段（warmupSec）以减少 shader 编译等抖动影响。
- 记录 RunContext： OS/驱动/分辨率/电源策略，保证可解释性与可对比性。

### 5.2 可观测性
- Run 状态机完整：Pending → Running → Completed/Failed/Aborted
- 统一日志归档：启动命令、stdout/stderr、外部工具产物路径、异常原因。

### 5.3 插件化与可扩展
- 指标采集 Provider 插件化：CpuMemProvider/GpuProvider/FpsProvider 可替换。
- LLM 仅作为 ScriptGenerator 插件，核心执行链路不依赖 LLM。
- OpenGL 注入作为可选模块，不影响主系统通用性（OpenGL/Vulkan/DX 均可走系统级采样主链路）。

## 6. 部署架构
单机部署：
- API Service + DB + Runner/Collector 在同一主机
- Web UI 本地或浏览器访问
